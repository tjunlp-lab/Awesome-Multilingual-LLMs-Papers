# Awesome-Multilingual-LLMs-Papers

This repository contains list of papers according to [our survey](https://arxiv.org/pdf/2310.19736.pdf):

<p align="center"><strong>Multilingual Large Language Models: A Systematic Survey</strong></p>

<p align="center">Shaolin Zhu<sup>1</sup>,   Supryadi<sup>1</sup>,   Shaoyang Xu<sup>1</sup>,   Haoran Sun<sup>1</sup>,   Leiyu Pan<sup>1</sup>,   Menglong Cui<sup>1</sup>, </p>

<p align="center">Jiangcun Du<sup>1</sup>,   Renren Jin<sup>1</sup>,   António Branco<sup>2</sup>†,   Deyi Xiong<sup>1</sup>†*</p>

<p align="center"><sup>1</sup>TJUNLP Lab, College of Intelligence and Computing, Tianjin University</p>

<p align="center"><sup>2</sup>NLX, Department of Informatics, University of Lisbon</p>

<p align="center">(*: Corresponding author, †: Advisory role)</p>

<div align=center>
    <img src="./assets/fig.png" style="zoom:30%"/>
</div>

## Papers

### Multilingual Evaluation

#### Tokenizer Evaluation

1. **"How Good is Your Tokenizer? On the Monolingual Performance of Multilingual Language Models"**. 
   
    *Phillip Rust et al.* ACL-IJCNLP 2021. [[Paper](https://aclanthology.org/2021.acl-long.243.pdf)] [[GitHub](https://github.com/Adapter-Hub/hgiyt)] 
   
2. **"ByT5: Towards a Token-Free Future with Pre-trained Byte-to-Byte Models"**. 

    *Linting Xue et al.* TACL 2023. [[Paper](https://aclanthology.org/2022.tacl-1.17.pdf)] [[GitHub](https://github.com/google-research/byt5)]

3. **"Language Model Tokenizers Introduce Unfairness Between Languages"**. 

    *Aleksandar Petrov et al.* NeurIPS 2023. [[Paper](https://arxiv.org/pdf/2305.15425)] [[GitHub](https://github.com/AleksandarPetrov/tokenization-fairness)]

4. **"Tokenizer Choice For LLM Training: Negligible or Crucial?"**. 

    *Mehdi Ali et al.* NAACL (Findings) 2024. [[Paper](https://aclanthology.org/2024.findings-naacl.247.pdf)]

#### Multilingual Evaluation Benchmarks and Datasets

##### Multilingual Holistic Evaluation

1. **"MEGA: Multilingual Evaluation of Generative AI"**. 
   
    *Kabir Ahuja et al.* EMNLP 2023. [[Paper](https://aclanthology.org/2023.emnlp-main.258.pdf)] [[GitHub](https://github.com/microsoft/Multilingual-Evaluation-of-Generative-AI-MEGA)] 
   
2. **"MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks"**. 

   *Kabir Ahuja et al.* arXiv 2024. [[Paper](https://arxiv.org/pdf/2311.07463)]

3. **"ByT5: Towards a Token-Free Future with Pre-trained Byte-to-Byte Models"**. 

    *Viet Dac Lai et al.* EMNLP (Findings) 2023. [[Paper](https://aclanthology.org/2023.findings-emnlp.878.pdf)]
##### Multilingual Task-Specific Evaluation
